{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs comprehensive exploratory data analysis on the California Housing dataset.\n",
    "\n",
    "## Objectives\n",
    "1. Load and understand the dataset\n",
    "2. Assess data quality\n",
    "3. Clean and preprocess data\n",
    "4. Engineer features\n",
    "5. Perform statistical analysis\n",
    "6. Generate visualizations\n",
    "7. Demonstrate SQL operations\n",
    "8. Derive insights for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.dataset import HousingDataProcessor\n",
    "from src.services.database import DatabaseManager\n",
    "from src.plots import EDAAnalyser\n",
    "from src.config import *\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "# Plotting settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"✅ All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data processor\n",
    "processor = HousingDataProcessor()\n",
    "\n",
    "# Load California housing data\n",
    "data = processor.load_data()\n",
    "\n",
    "print(f\"\\nDataset shape: {data.shape}\")\n",
    "print(f\"Rows: {data.shape[0]:,}\")\n",
    "print(f\"Columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"Last 5 rows:\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset info\n",
    "print(\"Dataset Information:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing Values Check:\")\n",
    "missing = processor.check_missing_values()\n",
    "\n",
    "if len(missing) == 0:\n",
    "    print(\"\\n✅ No missing values found!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ Found missing values in {len(missing)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicates = data.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicates}\")\n",
    "\n",
    "if duplicates == 0:\n",
    "    print(\"✅ No duplicates found!\")\n",
    "else:\n",
    "    print(f\"⚠️ Found {duplicates} duplicate rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types\n",
    "print(\"Data Types:\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"Handling missing values...\")\n",
    "cleaned_data = processor.handle_missing_values(strategy='median')\n",
    "\n",
    "print(f\"\\nBefore: {data.shape[0]:,} rows\")\n",
    "print(f\"After: {cleaned_data.shape[0]:,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "print(\"Removing outliers using IQR method...\")\n",
    "cleaned_data = processor.remove_outliers(method='iqr', threshold=1.5)\n",
    "\n",
    "print(f\"\\nFinal cleaned dataset: {cleaned_data.shape[0]:,} rows\")\n",
    "print(f\"Removed: {data.shape[0] - cleaned_data.shape[0]:,} rows ({((data.shape[0] - cleaned_data.shape[0])/data.shape[0]*100):.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply feature engineering\n",
    "print(\"Applying feature engineering...\")\n",
    "engineered_data = processor.apply_feature_engineering()\n",
    "\n",
    "print(f\"\\nOriginal features: {cleaned_data.shape[1]}\")\n",
    "print(f\"With engineered features: {engineered_data.shape[1]}\")\n",
    "print(f\"\\nNew features added: {engineered_data.shape[1] - cleaned_data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display engineered features\n",
    "print(\"Engineered Features:\")\n",
    "new_cols = [col for col in engineered_data.columns if col not in data.columns]\n",
    "print(new_cols)\n",
    "\n",
    "# Show sample of engineered features\n",
    "engineered_data[['rooms_per_household', 'bedrooms_per_room', \n",
    "                'population_per_household', 'income_category', 'age_category']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate engineered features\n",
    "print(\"Validating feature calculations...\")\n",
    "\n",
    "# Check rooms per household\n",
    "sample_idx = 0\n",
    "calculated_rooms = engineered_data.loc[sample_idx, 'total_rooms'] / engineered_data.loc[sample_idx, 'households']\n",
    "stored_rooms = engineered_data.loc[sample_idx, 'rooms_per_household']\n",
    "\n",
    "print(f\"Sample validation for rooms_per_household:\")\n",
    "print(f\"  Calculated: {calculated_rooms:.2f}\")\n",
    "print(f\"  Stored: {stored_rooms:.2f}\")\n",
    "print(f\"  Match: {np.isclose(calculated_rooms, stored_rooms)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Summary Statistics:\")\n",
    "engineered_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable distribution\n",
    "print(\"Target Variable (median_house_value) Statistics:\")\n",
    "target_stats = engineered_data['median_house_value'].describe()\n",
    "print(target_stats)\n",
    "\n",
    "print(f\"\\nRange: ${target_stats['min']:,.0f} - ${target_stats['max']:,.0f}\")\n",
    "print(f\"Mean: ${target_stats['mean']:,.0f}\")\n",
    "print(f\"Median: ${target_stats['50%']:,.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of each numeric feature\n",
    "numeric_cols = engineered_data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"Numeric Features:\")\n",
    "for col in numeric_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {engineered_data[col].mean():.2f}\")\n",
    "    print(f\"  Median: {engineered_data[col].median():.2f}\")\n",
    "    print(f\"  Std: {engineered_data[col].std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "target_corr = engineered_data.select_dtypes(include=[np.number]).corr()['median_house_value'].sort_values(ascending=False)\n",
    "\n",
    "print(\"Correlations with Median House Value:\")\n",
    "print(\"=\"*50)\n",
    "print(target_corr)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 positive correlations\n",
    "print(\"Top 5 Features with Highest Positive Correlation:\")\n",
    "top_5_positive = target_corr[target_corr < 1.0].head(5)\n",
    "print(top_5_positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 negative correlations\n",
    "print(\"Top 5 Features with Highest Negative Correlation:\")\n",
    "top_5_negative = target_corr.tail(5)\n",
    "print(top_5_negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize EDA Analyser\n",
    "print(\"Initializing EDA Analyser...\")\n",
    "eda = EDAAnalyser(engineered_data)\n",
    "\n",
    "print(\"\\nGenerating all visualizations...\")\n",
    "print(\"This may take a few moments...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all 10 visualizations\n",
    "plots = eda.generate_all_plots()\n",
    "\n",
    "print(f\"\\n✅ Generated {len(plots)} visualizations!\")\n",
    "print(f\"Saved to: {FIGURES_DIR}\")\n",
    "\n",
    "for plot_name, path in plots.items():\n",
    "    print(f\"  - {plot_name}: {Path(path).name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correlation analysis\n",
    "print(\"Detailed Correlation Analysis:\")\n",
    "correlations = eda.get_correlation_analysis('median_house_value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SQL Demonstrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database manager\n",
    "print(\"Initializing Database Manager...\")\n",
    "db = DatabaseManager()\n",
    "\n",
    "# Create tables\n",
    "print(\"\\nCreating database tables...\")\n",
    "db.create_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert data into database\n",
    "print(\"Inserting data into database...\")\n",
    "db.insert_data(engineered_data, 'housing')\n",
    "\n",
    "print(\"\\nPopulating district summary table...\")\n",
    "db.populate_district_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration 1: WHERE clause filtering\n",
    "print(\"=\" * 60)\n",
    "print(\"SQL Demonstration 1: WHERE Clause\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nQuery: Filter houses with income between $30k-$50k\")\n",
    "filtered = db.filter_by_income(3.0, 5.0)\n",
    "\n",
    "print(f\"\\nFound {len(filtered):,} records\")\n",
    "print(\"\\nSample results:\")\n",
    "filtered[['longitude', 'latitude', 'median_income', 'median_house_value']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration 2: GROUP BY aggregation\n",
    "print(\"=\" * 60)\n",
    "print(\"SQL Demonstration 2: GROUP BY Aggregation\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nQuery: Aggregate statistics by income category\")\n",
    "aggregated = db.aggregate_by_income_category()\n",
    "\n",
    "print(\"\\nAggregated Results:\")\n",
    "aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration 3: INNER JOIN\n",
    "print(\"=\" * 60)\n",
    "print(\"SQL Demonstration 3: INNER JOIN\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nQuery: Join housing with district summary\")\n",
    "joined = db.join_housing_with_summary(limit=20)\n",
    "\n",
    "print(f\"\\nJoined {len(joined):,} records\")\n",
    "print(\"\\nSample results showing individual houses vs district averages:\")\n",
    "joined[['income_category', 'median_house_value', 'district_avg_value', \n",
    "        'rooms_per_household', 'district_avg_rooms']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database statistics\n",
    "print(\"Database Statistics:\")\n",
    "stats = db.get_statistics()\n",
    "\n",
    "print(f\"\\nHousing records: {stats['housing_count']:,}\")\n",
    "print(f\"Summary records: {stats['summary_count']:,}\")\n",
    "print(f\"Database size: {stats['database_size']:.2f} MB\")\n",
    "print(f\"Tables: {stats['tables']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Key Insights & Conclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"KEY INSIGHTS FROM EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Top correlations\n",
    "print(\"\\n1. TOP 3 FEATURES CORRELATED WITH HOUSE PRICES:\")\n",
    "top_3 = target_corr[target_corr < 1.0].head(3)\n",
    "for i, (feature, corr) in enumerate(top_3.items(), 1):\n",
    "    print(f\"   {i}. {feature}: {corr:.3f}\")\n",
    "\n",
    "# Geographic patterns\n",
    "print(\"\\n2. GEOGRAPHIC PATTERNS:\")\n",
    "print(f\"   - Latitude range: {engineered_data['latitude'].min():.2f} to {engineered_data['latitude'].max():.2f}\")\n",
    "print(f\"   - Longitude range: {engineered_data['longitude'].min():.2f} to {engineered_data['longitude'].max():.2f}\")\n",
    "print(f\"   - Data covers California state\")\n",
    "\n",
    "# Income impact\n",
    "print(\"\\n3. INCOME IMPACT:\")\n",
    "income_groups = aggregated.sort_values('avg_house_value', ascending=False)\n",
    "for _, row in income_groups.iterrows():\n",
    "    print(f\"   - {row['income_category'].title()}: ${row['avg_house_value']:,.0f} (n={row['count_districts']:,})\")\n",
    "\n",
    "# Housing characteristics\n",
    "print(\"\\n4. HOUSING CHARACTERISTICS:\")\n",
    "print(f\"   - Average rooms per household: {engineered_data['rooms_per_household'].mean():.2f}\")\n",
    "print(f\"   - Average bedrooms per room: {engineered_data['bedrooms_per_room'].mean():.2f}\")\n",
    "print(f\"   - Average population per household: {engineered_data['population_per_household'].mean():.2f}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\n5. RECOMMENDATIONS FOR MODELING:\")\n",
    "print(f\"   ✓ Use median_income as primary predictor (correlation: {target_corr['median_income']:.3f})\")\n",
    "print(f\"   ✓ Include geographic features (latitude, longitude)\")\n",
    "print(f\"   ✓ Leverage engineered features (rooms_per_household, etc.)\")\n",
    "print(f\"   ✓ Consider non-linear relationships for income\")\n",
    "print(f\"   ✓ Account for outliers in house values\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "print(\"Saving processed data...\")\n",
    "processor.save_data(engineered_data, 'processed')\n",
    "\n",
    "print(\"\\n✅ All data exported successfully!\")\n",
    "print(f\"\\nProcessed data available at: {PROCESSED_DATA_PATH}\")\n",
    "print(f\"Database available at: {DATABASE_PATH}\")\n",
    "print(f\"Visualizations available at: {FIGURES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook has completed comprehensive exploratory data analysis on the California Housing dataset:\n",
    "\n",
    "✅ **Data Loading**: Loaded 20,640 housing records with 8 original features\n",
    "\n",
    "✅ **Data Quality**: Checked for missing values, duplicates, and outliers\n",
    "\n",
    "✅ **Data Cleaning**: Handled missing values and removed outliers\n",
    "\n",
    "✅ **Feature Engineering**: Created 5 new features (rooms_per_household, bedrooms_per_room, population_per_household, income_category, age_category)\n",
    "\n",
    "✅ **Statistical Analysis**: Performed univariate, bivariate, and multivariate analysis\n",
    "\n",
    "✅ **Visualizations**: Generated 10 different types of plots\n",
    "\n",
    "✅ **SQL Operations**: Demonstrated WHERE, GROUP BY, and INNER JOIN queries\n",
    "\n",
    "✅ **Insights**: Identified key patterns and relationships\n",
    "\n",
    "**Next Steps**:\n",
    "1. Train linear regression model using processed data\n",
    "2. Evaluate model performance\n",
    "3. Make predictions using the Streamlit dashboard\n",
    "\n",
    "**Files Generated**:\n",
    "- Processed CSV: `data/processed/housing_processed.csv`\n",
    "- SQLite Database: `data/housing.db`\n",
    "- Visualizations: `reports/figures/*.png` (10 plots)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
